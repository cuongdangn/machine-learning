{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000, 1)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000, 1)\n",
      "numclass:  10\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  MaxPooling2D,MaxPooling1D,ConvLSTM2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import  Convolution2D as Conv2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "print('numclass: ',num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]\n",
      " [8]\n",
      " [8]\n",
      " ..., \n",
      " [5]\n",
      " [1]\n",
      " [7]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Normalise data to [0, 1] range\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train = (X_train*0.8+25.5)/np.max(X_train)\n",
    "X_test  = (X_test*0.8+25.5)/np.max(X_test)\n",
    "\n",
    "\n",
    "print(y_test)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels : create maxtrix y[i][j] = 1 if y[i] = j\n",
    "y_test = np_utils.to_categorical(y_test, num_classes) \n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 input_shape=(32,32,3),activation='relu',padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(1, 1),activation='relu',padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.3)) \n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(1, 1),activation='relu',padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(1, 1),activation='relu',padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 307s 6ms/step - loss: 1.6911 - acc: 0.3840 - val_loss: 1.4776 - val_acc: 0.4654\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 304s 6ms/step - loss: 1.4033 - acc: 0.4899 - val_loss: 1.2262 - val_acc: 0.5542\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 1.2456 - acc: 0.5510 - val_loss: 1.0815 - val_acc: 0.6144\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 1.1362 - acc: 0.5971 - val_loss: 1.0083 - val_acc: 0.6407\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 1.0511 - acc: 0.6284 - val_loss: 1.0462 - val_acc: 0.6240\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.9860 - acc: 0.6521 - val_loss: 0.8728 - val_acc: 0.6939\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.9217 - acc: 0.6753 - val_loss: 0.8337 - val_acc: 0.7051\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.8706 - acc: 0.6949 - val_loss: 0.7894 - val_acc: 0.7259\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.8221 - acc: 0.7099 - val_loss: 0.7540 - val_acc: 0.7390\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.7809 - acc: 0.7269 - val_loss: 0.7673 - val_acc: 0.7306\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.7417 - acc: 0.7393 - val_loss: 0.7431 - val_acc: 0.7431\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.7084 - acc: 0.7498 - val_loss: 0.7262 - val_acc: 0.7496\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.6779 - acc: 0.7605 - val_loss: 0.6843 - val_acc: 0.7655\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.6469 - acc: 0.7730 - val_loss: 0.6847 - val_acc: 0.7629\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.6198 - acc: 0.7828 - val_loss: 0.6799 - val_acc: 0.7645\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.5966 - acc: 0.7893 - val_loss: 0.6462 - val_acc: 0.7777\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.5668 - acc: 0.7989 - val_loss: 0.6471 - val_acc: 0.7765\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.5364 - acc: 0.8104 - val_loss: 0.6445 - val_acc: 0.7793\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.5213 - acc: 0.8154 - val_loss: 0.6381 - val_acc: 0.7842\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.5061 - acc: 0.8202 - val_loss: 0.6561 - val_acc: 0.7791\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.4834 - acc: 0.8293 - val_loss: 0.6358 - val_acc: 0.7842\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.4642 - acc: 0.8357 - val_loss: 0.6387 - val_acc: 0.7858\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.4469 - acc: 0.8423 - val_loss: 0.6192 - val_acc: 0.7917\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 301s 6ms/step - loss: 0.4284 - acc: 0.8473 - val_loss: 0.6211 - val_acc: 0.7899\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 300s 6ms/step - loss: 0.4193 - acc: 0.8506 - val_loss: 0.6360 - val_acc: 0.7881\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 291s 6ms/step - loss: 0.4060 - acc: 0.8535 - val_loss: 0.6430 - val_acc: 0.7851\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3916 - acc: 0.8612 - val_loss: 0.6267 - val_acc: 0.7936\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3776 - acc: 0.8638 - val_loss: 0.6239 - val_acc: 0.7954\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3669 - acc: 0.8680 - val_loss: 0.6416 - val_acc: 0.7949\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.3615 - acc: 0.8706 - val_loss: 0.6636 - val_acc: 0.7849\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3412 - acc: 0.8769 - val_loss: 0.6431 - val_acc: 0.7891\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.3397 - acc: 0.8788 - val_loss: 0.6275 - val_acc: 0.7932\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3272 - acc: 0.8828 - val_loss: 0.6519 - val_acc: 0.7919\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.3223 - acc: 0.8840 - val_loss: 0.6477 - val_acc: 0.7970\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.3111 - acc: 0.8886 - val_loss: 0.6616 - val_acc: 0.7906\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 292s 6ms/step - loss: 0.3065 - acc: 0.8896 - val_loss: 0.6311 - val_acc: 0.7958\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2964 - acc: 0.8944 - val_loss: 0.6653 - val_acc: 0.7926\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2886 - acc: 0.8971 - val_loss: 0.6457 - val_acc: 0.7976\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2811 - acc: 0.8994 - val_loss: 0.6846 - val_acc: 0.7912\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2767 - acc: 0.9008 - val_loss: 0.6689 - val_acc: 0.7952\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2705 - acc: 0.9023 - val_loss: 0.6229 - val_acc: 0.8050\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2675 - acc: 0.9032 - val_loss: 0.6453 - val_acc: 0.7952\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2606 - acc: 0.9074 - val_loss: 0.6579 - val_acc: 0.8001\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2521 - acc: 0.9093 - val_loss: 0.6757 - val_acc: 0.7996\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2494 - acc: 0.9120 - val_loss: 0.6587 - val_acc: 0.7973\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2398 - acc: 0.9141 - val_loss: 0.6705 - val_acc: 0.7989\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2438 - acc: 0.9131 - val_loss: 0.6652 - val_acc: 0.7992\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2366 - acc: 0.9144 - val_loss: 0.6649 - val_acc: 0.7984\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2330 - acc: 0.9175 - val_loss: 0.6636 - val_acc: 0.8050\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2314 - acc: 0.9161 - val_loss: 0.6839 - val_acc: 0.7955\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2260 - acc: 0.9200 - val_loss: 0.6590 - val_acc: 0.8035\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2236 - acc: 0.9198 - val_loss: 0.6800 - val_acc: 0.7959\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2183 - acc: 0.9220 - val_loss: 0.6667 - val_acc: 0.8012\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2161 - acc: 0.9237 - val_loss: 0.6874 - val_acc: 0.7969\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.2114 - acc: 0.9249 - val_loss: 0.6829 - val_acc: 0.8009\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2102 - acc: 0.9260 - val_loss: 0.6796 - val_acc: 0.8009\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.2077 - acc: 0.9259 - val_loss: 0.6967 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.2020 - acc: 0.9278 - val_loss: 0.6810 - val_acc: 0.7984\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.2048 - acc: 0.9268 - val_loss: 0.6877 - val_acc: 0.8014\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.2022 - acc: 0.9268 - val_loss: 0.7005 - val_acc: 0.7990\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1997 - acc: 0.9290 - val_loss: 0.6715 - val_acc: 0.8030\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1917 - acc: 0.9310 - val_loss: 0.6898 - val_acc: 0.8003\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1887 - acc: 0.9322 - val_loss: 0.6677 - val_acc: 0.8094\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1908 - acc: 0.9308 - val_loss: 0.6795 - val_acc: 0.8057\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1870 - acc: 0.9347 - val_loss: 0.7051 - val_acc: 0.7971\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1820 - acc: 0.9348 - val_loss: 0.6921 - val_acc: 0.8021\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1796 - acc: 0.9360 - val_loss: 0.7236 - val_acc: 0.8013\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1809 - acc: 0.9354 - val_loss: 0.6903 - val_acc: 0.8023\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1774 - acc: 0.9359 - val_loss: 0.6816 - val_acc: 0.8033\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 0.1731 - acc: 0.9382 - val_loss: 0.6923 - val_acc: 0.8040\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1737 - acc: 0.9385 - val_loss: 0.7137 - val_acc: 0.8006\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 0.1718 - acc: 0.9384 - val_loss: 0.7132 - val_acc: 0.7990\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1708 - acc: 0.9389 - val_loss: 0.7115 - val_acc: 0.7991\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1704 - acc: 0.9405 - val_loss: 0.6973 - val_acc: 0.8007\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1655 - acc: 0.9407 - val_loss: 0.6833 - val_acc: 0.8055\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1697 - acc: 0.9398 - val_loss: 0.7195 - val_acc: 0.8046\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1647 - acc: 0.9410 - val_loss: 0.7042 - val_acc: 0.8074\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1582 - acc: 0.9439 - val_loss: 0.6849 - val_acc: 0.8097\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1642 - acc: 0.9414 - val_loss: 0.7045 - val_acc: 0.8025\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1650 - acc: 0.9411 - val_loss: 0.7188 - val_acc: 0.8011\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1593 - acc: 0.9436 - val_loss: 0.7103 - val_acc: 0.8005\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1607 - acc: 0.9431 - val_loss: 0.7019 - val_acc: 0.8054\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1548 - acc: 0.9450 - val_loss: 0.7206 - val_acc: 0.8001\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.1527 - acc: 0.9463 - val_loss: 0.7186 - val_acc: 0.8080\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1504 - acc: 0.9461 - val_loss: 0.7226 - val_acc: 0.8051\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1517 - acc: 0.9459 - val_loss: 0.7167 - val_acc: 0.8062\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1518 - acc: 0.9469 - val_loss: 0.7186 - val_acc: 0.8034\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1457 - acc: 0.9499 - val_loss: 0.7130 - val_acc: 0.8107\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1491 - acc: 0.9477 - val_loss: 0.7126 - val_acc: 0.8116\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1477 - acc: 0.9477 - val_loss: 0.7020 - val_acc: 0.8080\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1460 - acc: 0.9485 - val_loss: 0.7176 - val_acc: 0.8077\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 299s 6ms/step - loss: 0.1439 - acc: 0.9479 - val_loss: 0.7138 - val_acc: 0.8059\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 302s 6ms/step - loss: 0.1411 - acc: 0.9495 - val_loss: 0.7166 - val_acc: 0.8055\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.1410 - acc: 0.9508 - val_loss: 0.7218 - val_acc: 0.8046\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 295s 6ms/step - loss: 0.1431 - acc: 0.9491 - val_loss: 0.7131 - val_acc: 0.8076\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 303s 6ms/step - loss: 0.1370 - acc: 0.9521 - val_loss: 0.7327 - val_acc: 0.8064\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 302s 6ms/step - loss: 0.1414 - acc: 0.9503 - val_loss: 0.7164 - val_acc: 0.8085\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 304s 6ms/step - loss: 0.1422 - acc: 0.9496 - val_loss: 0.7343 - val_acc: 0.8043\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 303s 6ms/step - loss: 0.1375 - acc: 0.9504 - val_loss: 0.7108 - val_acc: 0.8060\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 303s 6ms/step - loss: 0.1369 - acc: 0.9511 - val_loss: 0.7349 - val_acc: 0.8069\n"
     ]
    }
   ],
   "source": [
    "optimiz = keras.optimizers.adam(lr=0.0002)\n",
    "\n",
    "model.compile(optimizer=optimiz,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,                # Train the model using the training set...\n",
    "          batch_size=32, epochs=100, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERHpoFAQEZEO/x/7K90TkZfFNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d1afd977b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#p\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title(\"Loss value\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend(['loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 38s 4ms/step\n",
      "[0.73488177099227903, 0.80689999999999995]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
