{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000, 1)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000, 1)\n",
      "numclass:  10\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  MaxPooling2D,MaxPooling1D,ConvLSTM2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import  Convolution2D as Conv2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#load data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "num_classes = np.unique(y_train).shape[0]\n",
    "print('numclass: ',num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]\n",
      " [8]\n",
      " [8]\n",
      " ..., \n",
      " [5]\n",
      " [1]\n",
      " [7]]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Normalise data to [0, 1] range\n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32')\n",
    "X_train = (X_train*0.8+25.5)/np.max(X_train)\n",
    "X_test  = (X_test*0.8+25.5)/np.max(X_test)\n",
    "\n",
    "\n",
    "print(y_test)\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_classes) # One-hot encode the labels : create maxtrix y[i][j] = 1 if y[i] = j\n",
    "y_test = np_utils.to_categorical(y_test, num_classes) \n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 input_shape=(32,32,3),activation='relu',padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(1, 1),activation='relu',padding='same'))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.3)) \n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(1, 1),activation='relu',padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(1, 1),activation='relu',padding='same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3),activation='relu',padding='same'))\n",
    "\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 307s 6ms/step - loss: 1.6911 - acc: 0.3840 - val_loss: 1.4776 - val_acc: 0.4654\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 304s 6ms/step - loss: 1.4033 - acc: 0.4899 - val_loss: 1.2262 - val_acc: 0.5542\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 1.2456 - acc: 0.5510 - val_loss: 1.0815 - val_acc: 0.6144\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 1.1362 - acc: 0.5971 - val_loss: 1.0083 - val_acc: 0.6407\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 1.0511 - acc: 0.6284 - val_loss: 1.0462 - val_acc: 0.6240\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.9860 - acc: 0.6521 - val_loss: 0.8728 - val_acc: 0.6939\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.9217 - acc: 0.6753 - val_loss: 0.8337 - val_acc: 0.7051\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.8706 - acc: 0.6949 - val_loss: 0.7894 - val_acc: 0.7259\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.8221 - acc: 0.7099 - val_loss: 0.7540 - val_acc: 0.7390\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.7809 - acc: 0.7269 - val_loss: 0.7673 - val_acc: 0.7306\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.7417 - acc: 0.7393 - val_loss: 0.7431 - val_acc: 0.7431\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.7084 - acc: 0.7498 - val_loss: 0.7262 - val_acc: 0.7496\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.6779 - acc: 0.7605 - val_loss: 0.6843 - val_acc: 0.7655\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.6469 - acc: 0.7730 - val_loss: 0.6847 - val_acc: 0.7629\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.6198 - acc: 0.7828 - val_loss: 0.6799 - val_acc: 0.7645\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.5966 - acc: 0.7893 - val_loss: 0.6462 - val_acc: 0.7777\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.5668 - acc: 0.7989 - val_loss: 0.6471 - val_acc: 0.7765\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.5364 - acc: 0.8104 - val_loss: 0.6445 - val_acc: 0.7793\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.5213 - acc: 0.8154 - val_loss: 0.6381 - val_acc: 0.7842\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.5061 - acc: 0.8202 - val_loss: 0.6561 - val_acc: 0.7791\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.4834 - acc: 0.8293 - val_loss: 0.6358 - val_acc: 0.7842\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.4642 - acc: 0.8357 - val_loss: 0.6387 - val_acc: 0.7858\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.4469 - acc: 0.8423 - val_loss: 0.6192 - val_acc: 0.7917\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 301s 6ms/step - loss: 0.4284 - acc: 0.8473 - val_loss: 0.6211 - val_acc: 0.7899\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 300s 6ms/step - loss: 0.4193 - acc: 0.8506 - val_loss: 0.6360 - val_acc: 0.7881\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 291s 6ms/step - loss: 0.4060 - acc: 0.8535 - val_loss: 0.6430 - val_acc: 0.7851\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3916 - acc: 0.8612 - val_loss: 0.6267 - val_acc: 0.7936\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3776 - acc: 0.8638 - val_loss: 0.6239 - val_acc: 0.7954\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3669 - acc: 0.8680 - val_loss: 0.6416 - val_acc: 0.7949\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.3615 - acc: 0.8706 - val_loss: 0.6636 - val_acc: 0.7849\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3412 - acc: 0.8769 - val_loss: 0.6431 - val_acc: 0.7891\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.3397 - acc: 0.8788 - val_loss: 0.6275 - val_acc: 0.7932\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.3272 - acc: 0.8828 - val_loss: 0.6519 - val_acc: 0.7919\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.3223 - acc: 0.8840 - val_loss: 0.6477 - val_acc: 0.7970\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.3111 - acc: 0.8886 - val_loss: 0.6616 - val_acc: 0.7906\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 292s 6ms/step - loss: 0.3065 - acc: 0.8896 - val_loss: 0.6311 - val_acc: 0.7958\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2964 - acc: 0.8944 - val_loss: 0.6653 - val_acc: 0.7926\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2886 - acc: 0.8971 - val_loss: 0.6457 - val_acc: 0.7976\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2811 - acc: 0.8994 - val_loss: 0.6846 - val_acc: 0.7912\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2767 - acc: 0.9008 - val_loss: 0.6689 - val_acc: 0.7952\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2705 - acc: 0.9023 - val_loss: 0.6229 - val_acc: 0.8050\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2675 - acc: 0.9032 - val_loss: 0.6453 - val_acc: 0.7952\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2606 - acc: 0.9074 - val_loss: 0.6579 - val_acc: 0.8001\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2521 - acc: 0.9093 - val_loss: 0.6757 - val_acc: 0.7996\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2494 - acc: 0.9120 - val_loss: 0.6587 - val_acc: 0.7973\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2398 - acc: 0.9141 - val_loss: 0.6705 - val_acc: 0.7989\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2438 - acc: 0.9131 - val_loss: 0.6652 - val_acc: 0.7992\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2366 - acc: 0.9144 - val_loss: 0.6649 - val_acc: 0.7984\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2330 - acc: 0.9175 - val_loss: 0.6636 - val_acc: 0.8050\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2314 - acc: 0.9161 - val_loss: 0.6839 - val_acc: 0.7955\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2260 - acc: 0.9200 - val_loss: 0.6590 - val_acc: 0.8035\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.2236 - acc: 0.9198 - val_loss: 0.6800 - val_acc: 0.7959\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2183 - acc: 0.9220 - val_loss: 0.6667 - val_acc: 0.8012\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2161 - acc: 0.9237 - val_loss: 0.6874 - val_acc: 0.7969\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.2114 - acc: 0.9249 - val_loss: 0.6829 - val_acc: 0.8009\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 289s 6ms/step - loss: 0.2102 - acc: 0.9260 - val_loss: 0.6796 - val_acc: 0.8009\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.2077 - acc: 0.9259 - val_loss: 0.6967 - val_acc: 0.8000\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.2020 - acc: 0.9278 - val_loss: 0.6810 - val_acc: 0.7984\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.2048 - acc: 0.9268 - val_loss: 0.6877 - val_acc: 0.8014\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.2022 - acc: 0.9268 - val_loss: 0.7005 - val_acc: 0.7990\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1997 - acc: 0.9290 - val_loss: 0.6715 - val_acc: 0.8030\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1917 - acc: 0.9310 - val_loss: 0.6898 - val_acc: 0.8003\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1887 - acc: 0.9322 - val_loss: 0.6677 - val_acc: 0.8094\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1908 - acc: 0.9308 - val_loss: 0.6795 - val_acc: 0.8057\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1870 - acc: 0.9347 - val_loss: 0.7051 - val_acc: 0.7971\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1820 - acc: 0.9348 - val_loss: 0.6921 - val_acc: 0.8021\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1796 - acc: 0.9360 - val_loss: 0.7236 - val_acc: 0.8013\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1809 - acc: 0.9354 - val_loss: 0.6903 - val_acc: 0.8023\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1774 - acc: 0.9359 - val_loss: 0.6816 - val_acc: 0.8033\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 0.1731 - acc: 0.9382 - val_loss: 0.6923 - val_acc: 0.8040\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1737 - acc: 0.9385 - val_loss: 0.7137 - val_acc: 0.8006\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 285s 6ms/step - loss: 0.1718 - acc: 0.9384 - val_loss: 0.7132 - val_acc: 0.7990\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1708 - acc: 0.9389 - val_loss: 0.7115 - val_acc: 0.7991\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1704 - acc: 0.9405 - val_loss: 0.6973 - val_acc: 0.8007\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1655 - acc: 0.9407 - val_loss: 0.6833 - val_acc: 0.8055\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1697 - acc: 0.9398 - val_loss: 0.7195 - val_acc: 0.8046\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1647 - acc: 0.9410 - val_loss: 0.7042 - val_acc: 0.8074\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1582 - acc: 0.9439 - val_loss: 0.6849 - val_acc: 0.8097\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1642 - acc: 0.9414 - val_loss: 0.7045 - val_acc: 0.8025\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1650 - acc: 0.9411 - val_loss: 0.7188 - val_acc: 0.8011\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1593 - acc: 0.9436 - val_loss: 0.7103 - val_acc: 0.8005\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1607 - acc: 0.9431 - val_loss: 0.7019 - val_acc: 0.8054\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1548 - acc: 0.9450 - val_loss: 0.7206 - val_acc: 0.8001\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 288s 6ms/step - loss: 0.1527 - acc: 0.9463 - val_loss: 0.7186 - val_acc: 0.8080\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1504 - acc: 0.9461 - val_loss: 0.7226 - val_acc: 0.8051\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1517 - acc: 0.9459 - val_loss: 0.7167 - val_acc: 0.8062\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 286s 6ms/step - loss: 0.1518 - acc: 0.9469 - val_loss: 0.7186 - val_acc: 0.8034\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1457 - acc: 0.9499 - val_loss: 0.7130 - val_acc: 0.8107\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1491 - acc: 0.9477 - val_loss: 0.7126 - val_acc: 0.8116\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1477 - acc: 0.9477 - val_loss: 0.7020 - val_acc: 0.8080\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 287s 6ms/step - loss: 0.1460 - acc: 0.9485 - val_loss: 0.7176 - val_acc: 0.8077\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 299s 6ms/step - loss: 0.1439 - acc: 0.9479 - val_loss: 0.7138 - val_acc: 0.8059\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 302s 6ms/step - loss: 0.1411 - acc: 0.9495 - val_loss: 0.7166 - val_acc: 0.8055\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 290s 6ms/step - loss: 0.1410 - acc: 0.9508 - val_loss: 0.7218 - val_acc: 0.8046\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 295s 6ms/step - loss: 0.1431 - acc: 0.9491 - val_loss: 0.7131 - val_acc: 0.8076\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 303s 6ms/step - loss: 0.1370 - acc: 0.9521 - val_loss: 0.7327 - val_acc: 0.8064\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 302s 6ms/step - loss: 0.1414 - acc: 0.9503 - val_loss: 0.7164 - val_acc: 0.8085\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 304s 6ms/step - loss: 0.1422 - acc: 0.9496 - val_loss: 0.7343 - val_acc: 0.8043\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 303s 6ms/step - loss: 0.1375 - acc: 0.9504 - val_loss: 0.7108 - val_acc: 0.8060\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 303s 6ms/step - loss: 0.1369 - acc: 0.9511 - val_loss: 0.7349 - val_acc: 0.8069\n"
     ]
    }
   ],
   "source": [
    "optimiz = keras.optimizers.adam(lr=0.0002)\n",
    "\n",
    "model.compile(optimizer=optimiz,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,                # Train the model using the training set...\n",
    "          batch_size=32, epochs=100, validation_data=(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
